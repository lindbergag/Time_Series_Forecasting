---
title: "exploratory analysis tweets and price"
output: html_document
keep_md: yes
---

```{r setup-chunk, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = FALSE)
```

```{r}

if (!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
if (!require("tm")) install.packages("tm")
library(tm)
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)
if (!require("gridExtra")) install.packages("gridExtra")
library(gridExtra)
if (!require("lubridate")) install.packages("lubridate")
library(lubridate)
if (!require("xts")) install.packages("xts")
library(xts)
if (!require("zoo")) install.packages("zoo")
library(zoo)
if (!require("SnowballC")) install.packages("SnowballC")
library(forecast)
```

Import data
```{r}
# read in csv file of tweets
rawish.data <- read.csv('influencerdata_clean.csv')
tweets <- rawish.data
```

```{r}
tweets$created_at <- as_datetime(tweets$created_at)
tweets$quoted_created_at <- as_datetime(tweets$quoted_created_at, tz = "UTC")
tweets$retweet_created_at <- as_datetime(tweets$retweet_created_at, tz = "UTC")
tweets$account_created_at <- as_datetime(tweets$account_created_at, tz = "UTC")

```

Clean hashtags
```{r}
# common artifacts that remain after cleaning
other.words <- c("rt", "amp","htt")

# remove all urls
tweets$hashtags <- gsub("(s?)(f|ht)tp(s?)://\\S+\\b", "", tweets$hashtags)


# clean data
tweets$hashtags <- tweets$hashtags %>%
  removeNumbers() %>%
  tolower() %>%
  iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT') %>% #Remove accents, foreign language items
  removeWords(stopwords("SMART")) %>%
  removeWords(other.words) %>%
  stemDocument() %>%
  stripWhitespace()

tweets$hashtags[tweets$hashtags == "NA"] <- NA

```

Clean symbols
```{r}
# common artifacts that remain after cleaning
other.words <- c("rt", "amp","htt")

# remove all urls
tweets$symbols <- gsub("(s?)(f|ht)tp(s?)://\\S+\\b", "", tweets$symbols)


# clean data
tweets$symbols <- tweets$symbols %>%
  removeNumbers() %>%
  tolower() %>%
  iconv(from = 'UTF-8', to = 'ASCII//TRANSLIT') %>% #Remove accents, foreign language items
  removeWords(stopwords("SMART")) %>%
  removeWords(other.words) %>%
  stemDocument() %>%
  stripWhitespace()

tweets$symbols[tweets$symbols == "NA"] <- NA


```

```{r}
ftm <- tweets %>%
  filter(symbols == "ftm") %>%
  mutate(hr = round_date(created_at, unit = "hour"))

ftm_summary <- ftm %>% count(hr)

ftm_summary %>% 
  ggplot() + 
  geom_line(aes(x = hr, y = n), alpha = .7) + # change alpha for readability 
  theme(axis.text.x = element_text(angle = 30)) + # make x-axis more readable
  ggtitle("Tweets per Hour") +
  xlab("") +
  ylab("Tweets")
```

```{r}

# read in the price data 
token_prices <- read_csv("tokenprices.csv")

ftm_prices <- token_prices %>%
  filter(coin_id == "fantom") %>%
  mutate(hr = round_date(timestamp, unit = "hour"))

```

```{r}
ggplot(ftm_prices) +
  geom_line(aes(x = hr, y = price)) +
  ggtitle("Price of FTM Over Time") +
  xlab("") +
  ylab("Price")

ggsave('ftmprice.png')
```

We don't have price data until 4/21, let's filter the tweets to then
```{r}
ftm <- ftm %>%
  filter(hr >= min(ftm_prices$hr)) 

ftm_summary <- ftm %>% count(hr)

ftm_summary %>% 
  ggplot() + 
  geom_col(aes(x = hr, y = n)) + # change alpha for readability 
  theme(axis.text.x = element_text(angle = 30)) + # make x-axis more readable
  ggtitle("Tweets per Hour") +
  xlab("") +
  ylab("Tweets")
```

First question, is there a relationship between tweet volume and price?
```{r}
#Merge the two tables
ftm_simple <- ftm_prices %>%
  select(hr, coin_id, price) %>%
  left_join(ftm_summary, by = c("hr" = "hr"))

# change nas to 0s 
ftm_simple <- ftm_simple %>% mutate(n = ifelse(is.na(n), 0, n))
```

Let's start with visualization
```{r}
ggplot(ftm_simple) +
  geom_point(aes(x = n, y = price)) +
    ggtitle("Price vs Tweets/Hour") +
  xlab("Tweets/Hour") +
  ylab("Price")
```

We're working with time series data, so it's a little more complicated
```{r}
tweet_volume <- ggplot(ftm_simple) +
  geom_col(aes(x = hr, y = n), color = "dark blue", alpha = 0.3) +
  ggtitle("Tweets/Price") +
  xlab("") +
  ylab("Tweets")
ftm_price <-  ggplot(ftm_simple) +
  geom_line(aes(x = hr, y = price), color = "orange") +
  xlab("") +
  ylab("Price")
grid.arrange(tweet_volume, ftm_price)
```

The first thing I notice is that we're looking at relatives and not hard quantities. For example, 10 Tweets in an hour in
summer 2021 is a large amount; whereas, 10 tweets in an hour in Jan 2022 is relatively normal.
We're going to want to look at the quantity in relation to several moving averages and then see how that correlates to price differences.

Before we do that, can we see if there is any kind of cycle to this price action (crypto is a 24-hour market, so perhaps time of day has an impact?)

```{r}
#extract the date and the hour
ftm_cycle <- ftm_simple %>%
  mutate(date = date(hr)) %>%
  mutate(hour = hour(hr))

#calculate min price per day, max price per day, and the time they occured
ftm_cycle <- ftm_cycle %>%
  group_by(date) %>%
  mutate(min_price = min(price),
         max_price = max(price),
         time_min = case_when(min_price == price ~ hour),
         time_max = case_when(max_price == price ~ hour),
  ) %>%
  ungroup()

tail(ftm_cycle, 25)
```

```{r}
min_time_summary <- ftm_cycle %>%
  count(time_min)
max_time_summary <- ftm_cycle %>%
  count(time_max)

min_time_plot <- ggplot(min_time_summary) +
  geom_col(aes(x = time_min, y = n), fill = "dark red") +
  ggtitle("Time of Day with the Lowest Prices") +
  xlab("Time of Day") +
  ylab("Days")
max_time_plot <- ggplot(max_time_summary) +
  geom_col(aes(x = time_max, y = n), fill = "dark green") +
  ggtitle("Time of Day with the Highest Prices") +
  xlab("Time of Day") +
  ylab("Days")

grid.arrange(min_time_plot, max_time_plot)
```
Okay.... sooo.... Highest and lowest prices happened between 23:00 and 00:00 on any given day
Highs seem more likely to be later in the day
And lows seem more likely to be later in the evening...
But... That still looks like mostly noise

```{r}
min_days <- ftm_cycle %>%
  group_by(date) %>%
  filter(time_min == 0) %>%
  count(time_max) %>%
  select(date)

ftm_cycle %>%
  filter(date %in% min_days$date) %>%
  count(time_max) %>%
  ggplot() +
  geom_col(aes(x = time_max, y = n)) +
  ggtitle("Time of Day with the Highest Prices when the Low was at 00:00") +
  xlab("Time of Day") +
  ylab("Days")  
```

```{r}
max_days <- ftm_cycle %>%
  group_by(date) %>%
  filter(time_max == 0) %>%
  count(time_min) %>%
  select(date)

ftm_cycle %>%
  filter(date %in% max_days$date) %>%
  count(time_min) %>%
  ggplot() +
  geom_col(aes(x = time_min, y = n)) +
  ggtitle("Time of Day with the Lowest Prices when the High was at 00:00") +
  xlab("Time of Day") +
  ylab("Days")  
```

Okay, so... let's stop goofing around. First, let's turn this into a time series object
```{r}
#Create a time series object from the data
ftm_simple <- ftm_simple %>%
  arrange(hr) %>%
  rename(tweets = n)
```

Quick visualization
```{r}
ftm_ts <- as.xts(ftm_simple[,3:4], order.by = ftm_simple$hr)
plot.xts(ftm_ts)
```

Let's look at the price differences over time
```{r}
plot.xts(diff(ftm_ts[,"price"]))
```
And tweets
```{r}

plot.xts(diff(ftm_ts[,"tweets"]))
```
Plot both?
```{r}
plot.xts(diff(ftm_ts))
```


Let's normalize so we can visualize better
```{r}
min_max_norm <- function(x) {
    (x - min(x)) / (max(x) - min(x))
}

standardized_ftm <- ftm_simple %>%
  mutate(price = min_max_norm(price)) %>%
  mutate(tweets = min_max_norm(tweets))

std_ts <- as.xts(standardized_ftm[,3:4], order.by = standardized_ftm$hr)
plot.xts(abs(diff(std_ts)))
```
Let's look at a daily rolling average
```{r}
ftm_ts$tweet_avg <- rollapply(ftm_ts$tweets, width = 24, FUN = mean)
plot.xts(ftm_ts$tweet_avg)
```
Let's look at a daily rolling average in price
```{r}
ftm_ts$price_avg <- rollapply(ftm_ts$price, width = 24, FUN = mean)
plot.xts(ftm_ts$price_avg)
```


What we're looking for is a spike in tweet volume relative to the mean
```{r}
ftm_ts$tweet_dev <- ftm_ts$tweets - ftm_ts$tweet_avg
plot.xts(ftm_ts$tweet_dev)
```
Let's look at price again
```{r}
ftm_ts$price_dev <- ftm_ts$price - ftm_ts$price_avg
plot.xts(ftm_ts$price_dev)
```
I might have gotten ahead of myself. We're trying to see if the price is trending in a direction and whether a tweet affects that
```{r}
ftm_ts$price_diff <- diff(ftm_ts$price, 1, 1)
plot.xts(ftm_ts$price_diff)
```
Now let's look at that rolling average of difference
```{r}
ftm_ts$price_diff_avg <- rollapply(ftm_ts$price_diff, width = 24, FUN = mean)
plot.xts(ftm_ts$price_diff_avg)
```

```{r}
ftm_ts$price_diff_dev <- ftm_ts$price_diff - ftm_ts$price_diff_avg
plot.xts(ftm_ts$price_diff_dev)
```

Now let's look and see if these things are correlated

```{r}
ftm_ts_df <- as.data.frame(ftm_ts)
fit.tweets <- lm(price_diff_dev ~ tweet_dev, ftm_ts_df)
summary(fit.tweets)
```
